{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72dbd89c-788e-4abd-9303-d7a41771708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4250eadc-c255-41e1-8542-a67122c03637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(uploaded_file):\n",
    "    image = Image.open(uploaded_file)\n",
    "    image = np.array(image)\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07f4fd04-edbf-4531-9457-e7c9700b868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateSSIM(template_img, query_img):\n",
    "    min_w = min(template_img.shape[1], query_img.shape[1])\n",
    "    min_h = min(template_img.shape[0], query_img.shape[0])\n",
    "    \n",
    "    img1 = cv2.resize(template_img, (min_w, min_h))\n",
    "    img2 = cv2.resize(query_img, (min_w, min_h))\n",
    "    \n",
    "    img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    score = ssim(img1, img2)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cc59afc-7aa8-471f-8ab8-dba13b6351cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeORB(template_img, query_img):\n",
    "    orb = cv2.ORB_create(nfeatures=700, scaleFactor=1.2, nlevels=8, edgeThreshold=15)\n",
    "    kpts1, descs1 = orb.detectAndCompute(template_img,None)\n",
    "    kpts2, descs2 = orb.detectAndCompute(query_img,None)\n",
    "    \n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(descs1, descs2)\n",
    "    dmatches = sorted(matches, key=lambda x: x.distance)\n",
    "    \n",
    "    src_pts = np.float32([kpts1[m.queryIdx].pt for m in dmatches]).reshape(-1,1,2)\n",
    "    dst_pts = np.float32([kpts2[m.trainIdx].pt for m in dmatches]).reshape(-1,1,2)\n",
    "    \n",
    "    if len(src_pts) < 4 or len(dst_pts) < 4:\n",
    "        print(\"Not enough keypoints for homography calculation\")\n",
    "        return None, None, None, None, None\n",
    "    \n",
    "    M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "    h, w = template_img.shape[:2]\n",
    "    pts = np.float32([[0,0],[0,h-1],[w-1,h-1],[w-1,0]]).reshape(-1,1,2)\n",
    "    \n",
    "    dst = cv2.perspectiveTransform(pts, M) if M is not None else None\n",
    "    return dst, dst_pts, kpts1, kpts2, dmatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86b0f98f-c808-492f-a3e5-85874eaeefc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values for specifying search area of features 1 to 7\n",
    "search_area_list = [[200,270,160,330],\n",
    "                    [1050,1500,250,400],\n",
    "                    [50,400,0,100],\n",
    "                    [750,1050,0,100],\n",
    "                    [850,1050,280,380],\n",
    "                    [700,820,290,370],\n",
    "                    [400,650,0,100]]\n",
    "\n",
    "# Values of max_area and min_area for each feature for features 1 to 7\n",
    "feature_area_limits_list = [[10000,14000],\n",
    "                            [9000,15000],\n",
    "                            [17000,21500],\n",
    "                            [19000,28000],\n",
    "                            [17500,23000],\n",
    "                            [6500,9000],\n",
    "                            [10000,16000]]\n",
    "score_set_list = []               # Stores the ssim score set of each feature\n",
    "best_extracted_img_list = []      # Stores the extracted image with highest SSIM score for each feature\n",
    "avg_ssim_list = []                # Stores the avg ssim value for each feature\n",
    "NUM_OF_FEATURES = 7               # Number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95da19a2-9f01-4a96-90d2-409f08c7b468",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algorithm 1\n",
    "def testFeature_1_2_7(gray_test_image, test_img, blur_test_img, denomination):\n",
    "    i = 0\n",
    "    j = 0\n",
    "    NUMBER_OF_TEMPLATES = 6\n",
    "    global score_set_list                # Stores the ssim score set of each feature\n",
    "    global best_extracted_img_list       # Stores the extracted image with highest SSIM score for each feature\n",
    "    global avg_ssim_list                 # Stores the avg ssim value for each feature\n",
    "\n",
    "    \n",
    "    #Progress bar\n",
    "    #global myProgress\n",
    "    #myProgress =myProgress['value']\n",
    "    \n",
    "    # Iterating for each feature\n",
    "    for j in range(NUM_OF_FEATURES):\n",
    "        print('ANALYSIS OF FEATURE ' + str(j+1))\n",
    "\n",
    "        score_set = []           # SSIM scores for each teamplate of current feature will be stored here\n",
    "        max_score = -1           # Stores max SSIM score\n",
    "        max_score_img = None     # Stores extraced image with max SSIM score for the current feature\n",
    "        \n",
    "        # Performing feature detection, extraction and comparison for each template stored in dataset \n",
    "        for i in range(NUMBER_OF_TEMPLATES):\n",
    "            print('---> Template ' + str(i+1) + ' :')\n",
    "            \n",
    "            # Current template \n",
    "            template_path = template_path = rf\"Dataset\\{denomination}_Features Dataset\\{j+1}\\{i+1}.jpg\"\n",
    "       \n",
    "            template_img = cv2.imread(template_path)\n",
    "            print(f\"Trying to load: {template_path}\")\n",
    " \n",
    "            template_img_blur = cv2.GaussianBlur(template_img, (5,5), 0)\n",
    "            template_img_gray = cv2.cvtColor(template_img_blur, cv2.COLOR_BGR2GRAY)\n",
    "            test_img_mask = gray_test_image.copy()\n",
    "            \n",
    "            # Creating a mask to search the current template.\n",
    "            search_area = search_area_list[j]\n",
    "\n",
    "            test_img_mask[:, :search_area[0]] = 0\n",
    "            test_img_mask[:, search_area[1]:] = 0\n",
    "            test_img_mask[:search_area[2], :] = 0\n",
    "            test_img_mask[search_area[3]:, :] = 0\n",
    "            \n",
    "            # Feature detection using ORB \n",
    "            dst, dst_pts, kpts1, kpts2, dmatches = computeORB(template_img_gray, test_img_mask)\n",
    "            \n",
    "            # Error handling\n",
    "            if dst is None:\n",
    "                print(f\"Skipping feature {j+1} due to insufficient matches.\")\n",
    "                continue\n",
    "            \n",
    "            query_img = test_img.copy()\n",
    "            \n",
    "            # drawing polygon around the region where the current template has been detected on the test currency note -- the blue polygon\n",
    "            res_img1 = cv2.polylines(query_img, [np.int32(dst)], True, (0,0,255), 1, cv2.LINE_AA)\n",
    "            st.image(res_img1, caption=\"Detected Feature\", use_column_width=True)\n",
    "            # draw match lines between the matched descriptors\n",
    "            res_img2 = cv2.drawMatches(template_img, kpts1, res_img1, kpts2, dmatches[:20],None,flags=2)\n",
    "            st.image(res_img2, caption=\"Matched Descriptors\", use_column_width=True)\n",
    "\n",
    "            # Find the details of a bounding rectangle that bounds the above polygon --- green rectangle\n",
    "            (x, y, w, h) = cv2.boundingRect(dst) # This gives us details about the rectangle that bounds this contour  \n",
    "            \n",
    "            # Checking if the area of the detected region is within the min and max area allowed for current feature \n",
    "            min_area = feature_area_limits_list[j][0]\n",
    "            max_area = feature_area_limits_list[j][1]\n",
    "\n",
    "            feature_area = w*h\n",
    "\n",
    "            if feature_area < min_area or feature_area > max_area:\n",
    "                (x, y, w, h) = cv2.boundingRect(dst_pts) \n",
    "\n",
    "                feature_area = w*h\n",
    "                if feature_area < min_area or feature_area > max_area: \n",
    "                    # If even area of 2nd rect is outside limits, then Discard current template\n",
    "                    print('Template Discarded- Area of extracted feature is outside permitted range!')\n",
    "                    continue\n",
    "\n",
    "            # Draw the rectangle\n",
    "            cv2.rectangle(res_img1, (x,y), (x+w, y+h), (0,255,0), 3)\n",
    "            st.image(res_img1, caption=\"Bounding Rectangle\", use_column_width=True)\n",
    "            \n",
    "\n",
    "            # SSIM calculation\n",
    "            # Crop out the region inside the green rectangle (matched region)\n",
    "            crop_img = blur_test_img[y:y+h, x:x+w]\n",
    "\n",
    "            plt.rcParams[\"figure.figsize\"] = (5, 5)\n",
    "            score = calculateSSIM(template_img_blur, crop_img)\n",
    "\n",
    "            score_set.append(score)\n",
    "            print('SSIM score: ', score, '\\n')\n",
    "            \n",
    "            # Keeping details about extracted region with highest SSIM score\n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                max_score_img = crop_img\n",
    "                \n",
    "            # #Progress bar- Updating the progess\n",
    "            # myProgress = myProgress + (75.0/(NUM_OF_FEATURES*NUMBER_OF_TEMPLATES))\n",
    "            # progress['value'] = myProgress \n",
    "            \n",
    "        # Storing necessary data\n",
    "        score_set_list.append(score_set)\n",
    "        print('SSIM score set of Feature ' + str(j+1) + ': ', score_set, '\\n')\n",
    "        \n",
    "        if len(score_set) != 0:\n",
    "            avg_ssim_list.append(sum(score_set)/len(score_set))\n",
    "            print('Average SSIM of Feature ' + str(j+1) + ': ',sum(score_set)/len(score_set),'\\n')\n",
    "        else:\n",
    "            print('No SSIM scores were found for this feature!')\n",
    "            avg_ssim_list.append(0.0)\n",
    "            print('Average SSIM of Feature ' + str(j+1) + ': 0','\\n')\n",
    "        \n",
    "        best_extracted_img_list.append([max_score_img, max_score])\n",
    "\n",
    "    # Printing all details for features 1- 7\n",
    "    print('Final Score- set list:','\\n')\n",
    "\n",
    "    for x in range(len(score_set_list)):\n",
    "        print('Feature',x+1,':',score_set_list[x])\n",
    "    print('\\n')\n",
    "\n",
    "    print('Final Average SSIM list for each feature:','\\n')\n",
    "\n",
    "    for x in range(len(avg_ssim_list)):\n",
    "        print('Feature',x+1,':',avg_ssim_list[x])\n",
    "        \n",
    "    results = []\n",
    "    for i, score in enumerate(avg_ssim_list):\n",
    "        status = \"Pass\" if score > 0.5 else \"Fail\"\n",
    "        results.append((max_score_img, score, status))\n",
    "\n",
    "    # Calculate average and max SSIM scores\n",
    "    all_scores = avg_ssim_list\n",
    "    avg_ssim = np.mean(all_scores) if all_scores else 0.0\n",
    "    max_ssim = np.max(all_scores) if all_scores else 0.0\n",
    "\n",
    "    # Return the results along with avg_ssim and max_ssim\n",
    "    return results, avg_ssim, max_ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81c9d871-9096-4a8b-96ad-829a602936d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algorithm 2\n",
    "def testFeature_8(image, denomination):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    if denomination == \"2000\":\n",
    "        crop = gray[80:230, 10:30]\n",
    "    else:\n",
    "        crop = gray[120:240, 12:35]\n",
    "    \n",
    "    _, thresh = cv2.threshold(crop, 130, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    whitePixelValue = 255      # White pixel   \n",
    "    blackPixelValue = 0        # Black pixel\n",
    "\n",
    "    width = thresh.shape[1]    # width of thresholded image\n",
    "\n",
    "    # Result will be stored here\n",
    "    result = []                # will contain the number of black regions in each column (if the colums is non- erroneos)\n",
    "    num_of_cols = 0            # will contain the number of non- erroneos columns\n",
    "\n",
    "    # Non erroneous columns are those columns which contains less noise.\n",
    "\n",
    "    print('Number of black regions found in each column: ')\n",
    "    \n",
    "    # iteration over each column in the cropped image\n",
    "    for j in range(width):\n",
    "        col =thresh[:, j:j+1]     # Extracting each column of thresholded image\n",
    "        count = 0                 # Counter to count number of black regions in each extracted column\n",
    "        \n",
    "        # Iterating over each row (or pixel) in the current columm\n",
    "        for i in range(len(col)-1):\n",
    "\n",
    "            # Taking two consecutive pixels and storing their intensity value\n",
    "            pixel1_value = col[i][0]\n",
    "            pixel2_value = col[i+1][0]\n",
    "\n",
    "            #----------------------------------------------\n",
    "            # This part modifies any error pixels, if present.\n",
    "            # Actually in a binary threshold, all pixels should be either white or black.\n",
    "            # If due to some error pixels other than white or black are present, then the pixel is taken as white pixel\n",
    "\n",
    "            if pixel1_value != 0 and pixel1_value != 255:\n",
    "                pixel1_value = 255\n",
    "            if pixel2_value != 0 and pixel2_value != 255:\n",
    "                pixel2_value = 255\n",
    "\n",
    "            #-------------------------------------------------\n",
    "\n",
    "\n",
    "            # If current pixel is white and next pixel is black, then increment the counter.\n",
    "            # This shows that a new black region has been discovered.\n",
    "            if pixel1_value == whitePixelValue and pixel2_value == blackPixelValue:\n",
    "                count += 1\n",
    "\n",
    "        # If the counter is less than 10, it is a valid column. (less noise is present)\n",
    "        if count > 0 and count < 10:\n",
    "            print(count)\n",
    "            result.append(count)\n",
    "            num_of_cols += 1\n",
    "        else:\n",
    "            # discard the count if it is too great e.g. count> 10 (Erroneous Column)\n",
    "            # This removes/ drops those columns which contain too much noise\n",
    "            print(count, 'Erroneous -> discarded') \n",
    "    \n",
    "    # Printing necessary details\n",
    "    print('\\nNumber of columns examined: ', width)\n",
    "    print('Number of non- erroneous columns found: ', num_of_cols)\n",
    "    \n",
    "    if num_of_cols != 0:\n",
    "        average_count = sum(result)/num_of_cols\n",
    "    else:\n",
    "        average_count = -1\n",
    "        print('Error occured- Division by 0')\n",
    "\n",
    "    print('\\nAverage number of black regions is: ', average_count)\n",
    "    \n",
    "    # Storing the thresholded image and average number of bleed lines detected \n",
    "    global left_BL_result\n",
    "    left_BL_result = [thresh, average_count]\n",
    "    return left_BL_result[1]\n",
    "\n",
    "def testFeature_9(image, denomination):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    if denomination == \"2000\":\n",
    "        crop = gray[90:230, 1140:1160]\n",
    "    else:\n",
    "        crop= gray[120:260, 1135:1155]\n",
    "    _, thresh = cv2.threshold(crop, 130, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    whitePixelValue = 255      # White pixel   \n",
    "    blackPixelValue = 0        # Black pixel\n",
    "\n",
    "    width = thresh.shape[1]    # width of thresholded image\n",
    "\n",
    "    # Result will be stored here\n",
    "    result = []                # will contain the number of black regions in each column (if the colums is non- erroneos)\n",
    "    num_of_cols = 0            # will contain the number of non- erroneos columns\n",
    "\n",
    "    # Non erroneous columns are those columns which contains less noise.\n",
    "\n",
    "    print('Number of black regions found in each column: ')\n",
    "    \n",
    "    # Iteration over each column in the cropped image\n",
    "    for j in range(width):\n",
    "        col =thresh[:, j:j+1]     # Extracting each column of thresholded image\n",
    "        count = 0                 # Counter to count number of black regions in each extracted column\n",
    "        \n",
    "        # Iterating over each row (or pixel) in the current columm\n",
    "        for i in range(len(col)-1):\n",
    "\n",
    "            # Taking two consecurive pixels and storing their intensity value\n",
    "            pixel1_value = col[i][0]\n",
    "            pixel2_value = col[i+1][0]\n",
    "\n",
    "            #----------------------------------------------\n",
    "            # This part modifies any error pixels, if present.\n",
    "            # Actually in a binary threshold, all pixels should be either white or black.\n",
    "            # If due to some error pixels other than white or black are present, then the pixel is taken as white pixel\n",
    "\n",
    "            if pixel1_value != 0 and pixel1_value != 255:\n",
    "                pixel1_value = 255\n",
    "            if pixel2_value != 0 and pixel2_value != 255:\n",
    "                pixel2_value = 255\n",
    "\n",
    "            #-------------------------------------------------\n",
    "\n",
    "            # If current pixel is white and next pixel is black, then increment the counter.\n",
    "            # This shows that a new black region has been discovered.\n",
    "            if pixel1_value == whitePixelValue and pixel2_value == blackPixelValue:\n",
    "                count += 1\n",
    "\n",
    "        # If the counter is less than 10, it is a valid column. (less noise is present)\n",
    "        if count > 0 and count < 10:\n",
    "            print(count)\n",
    "            result.append(count)\n",
    "            num_of_cols += 1\n",
    "        else:\n",
    "            # discard the count if it is too great e.g. count> 10 (Erroneous Column)\n",
    "            # This removes/ drops those columns which contain too much noise\n",
    "            print(count, 'Erroneous -> discarded')\n",
    "\n",
    "    # Printing necessary details\n",
    "    print('\\nNumber of columns examined: ', width)\n",
    "    print('Number of non- erroneous columns found: ', num_of_cols)\n",
    "\n",
    "    if num_of_cols != 0:\n",
    "        average_count = sum(result)/num_of_cols\n",
    "    else:\n",
    "        average_count = -1\n",
    "        print('Error occured- Division by 0')\n",
    "\n",
    "\n",
    "    print('\\nAverage number of black regions is: ', average_count)\n",
    "\n",
    "    # Storing the thresholded image and average number of bleed lines detected \n",
    "    global right_BL_result\n",
    "    right_BL_result = [thresh, average_count]\n",
    "    return right_BL_result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa3d372e-7d5f-42eb-b631-d307d69b4981",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algorithm 3\n",
    "def testFeature_10(image, denomination):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    crop = gray[360:440, 760:1080]\n",
    "    crop_bgr = image[360:440, 760:1080]\n",
    "\n",
    "    print('\\n\\nANALYSIS OF FEATURE 10 : NUMBER PANEL \\n')\n",
    "\n",
    "    test_passed = False        # If true, then the test is successful\n",
    "    res_img_list = []          # List of images of successful cases\n",
    "    count = 0                  # Stores number of cases whihc are successful\n",
    "    num = 1\n",
    "    \n",
    "    # THRESHOLDING at multiple values\n",
    "    # Start from 90 as threshold value, increase the threshold value by 5 every time and check if 9 characters are detected in the thresholded image of number panel\n",
    "    # If 9 characters are detected in at least one of the cases, the currency number panel is verified.\n",
    "    # If more than 1 cases pass, the best image will be choosen from the successful cases.\n",
    "    if denomination == \"2000\":\n",
    "        val = 90\n",
    "    else:\n",
    "        val = 95\n",
    "    for thresh_value in range(val, 155, 5):\n",
    "        # Thresholding at current value\n",
    "        _, thresh = cv2.threshold(crop, thresh_value, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        print('---> Threshold ' + str(num) + ' with Threshold value ' + str(thresh_value) + ' :')\n",
    "        num += 1\n",
    "\n",
    "        copy = crop_bgr.copy()\n",
    "\n",
    "        # Finding all the contours in the image of the number panel- CONTOUR DETECTION \n",
    "        img = cv2.bitwise_and(crop, crop, mask=thresh)\n",
    "        contours, hierarchy = cv2.findContours(img, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "        h_img, w_img = img.shape[:2]\n",
    "\n",
    "        # cv2.drawContours(copy, contours, -1, (0, 0, 255), 1)\n",
    "\n",
    "        # Storing the details of all the BOUNDING RECTANGLES for each contour\n",
    "        bounding_rect_list = []    \n",
    "\n",
    "        for contour in contours:\n",
    "            [x, y, w, h] = cv2.boundingRect(contour)\n",
    "\n",
    "            if x != 0:\n",
    "                bounding_rect_list.append([x,y,w,h])\n",
    "\n",
    "        # Sorting the list of rectangles\n",
    "        # Rectangles will get sorted according to the x coordinate of the top left corner\n",
    "        bounding_rect_list.sort()\n",
    "\n",
    "        # ELIMINATION OF ERRONEOUS RECTANGLES\n",
    "        # Min area is taken as 150\n",
    "        min_area = 150\n",
    "        res_list = []\n",
    "\n",
    "        # Storing all rectangles having area greater than the min_area in a separate list\n",
    "        for i in range(0, len(bounding_rect_list)):\n",
    "            if i>= len(bounding_rect_list):\n",
    "                break\n",
    "            if bounding_rect_list[i][2]*bounding_rect_list[i][3] > min_area:\n",
    "                res_list.append(bounding_rect_list[i])\n",
    "\n",
    "        # Eliminating the rectangles that are present within a bigger rectangle\n",
    "        i = 0\n",
    "        while i<len(res_list):\n",
    "            [x,y,w,h] = res_list[i]\n",
    "            j = i+1\n",
    "            while j<len(res_list):\n",
    "                [x0,y0,w0,h0] = res_list[j]\n",
    "\n",
    "                if (x+w) >= x0+w0:\n",
    "                    res_list.pop(j)\n",
    "                else:\n",
    "                    break\n",
    "            i+= 1\n",
    "\n",
    "        # Eliminating unnecessary rectangles\n",
    "        i = 0\n",
    "        while i<len(res_list):\n",
    "            [x,y,w,h] = res_list[i]\n",
    "\n",
    "            if (h_img-(y+h)) > 40:     #  Eliminating the rectangles whose lower edge is further away from lower edge of the image \n",
    "                res_list.pop(i)\n",
    "            elif h<17:\n",
    "                res_list.pop(i)        # Eliminating the rectangles whose height is less than 17 pixels    \n",
    "            else:\n",
    "                i += 1\n",
    "        \n",
    "        for rect in res_list:          # Drawing the remaining rectangles\n",
    "            [x,y,w,h] = rect\n",
    "            cv2.rectangle(copy, (x, y), (x + w, y + h), (0, 0, 255), 1)        \n",
    "\n",
    "        # COUNTING REMAINING RECTANGLES\n",
    "        # result of each image\n",
    "        if len(res_list) == 9:         # If number of rectangles detected is equal to 9, test passed\n",
    "            test_passed = True\n",
    "            res_img_list.append(copy)\n",
    "            count += 1\n",
    "            print('Test Successful: 9 letters found!')\n",
    "        else:\n",
    "            print('Unsuccessful!')\n",
    "\n",
    "        # If three consecutive cases pass the test, then break \n",
    "        if count == 3:\n",
    "            break\n",
    "\n",
    "    # Choosing the BEST IMAGE to be displayed   \n",
    "    # Even if a single case passes the test, then the currency number panel is verified.\n",
    "    # Selecting the best image to display\n",
    "    if count == 0:                    # If none of the cases passes the test\n",
    "        best_img = crop_bgr\n",
    "    elif count == 1:                  # If 1 case passes the test, then the image used in 1st case is selected as the best image\n",
    "        best_img = res_img_list[0]\n",
    "    elif count == 2:                  # If 2 cases pass the test, then the image used in 2nd case is selected as best image\n",
    "        best_img = res_img_list[1]\n",
    "    else:                             # If >= 3 cases pass the test, then the image used in 3rd case is selected as best image\n",
    "        best_img = res_img_list[2]\n",
    "       \n",
    "    \n",
    "    # Displaying final result\n",
    "\n",
    "    if(test_passed):\n",
    "        print('Test Passed!- 9 characters were detected in the serial number panel.')\n",
    "    else:\n",
    "        print('Test Failed!- 9 characters were NOT detected in the serial number panel.')\n",
    "    \n",
    "    # Storing the thresholded image and the result\n",
    "    global number_panel_result\n",
    "    number_panel_result = [best_img, test_passed]\n",
    "    return number_panel_result[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ca55271-5d6f-4702-8eca-ad02031fd4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c39dbcf2de4d1b9bf18a169ec1f949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Denomination:', options=('500', '2000'), value='500')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0368d54146a042f9bd46107e669d6b09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='.jpg,.png,.jpeg', description='Upload Image')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e75678d41f64e99ad28363711f713ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize widgets\n",
    "denomination_widget = widgets.Dropdown(\n",
    "    options=[\"500\", \"2000\"],\n",
    "    description='Denomination:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "upload_widget = widgets.FileUpload(\n",
    "    accept='.jpg,.png,.jpeg',\n",
    "    multiple=False,\n",
    "    description='Upload Image'\n",
    ")\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "# Create processing function\n",
    "def process_image(change):\n",
    "    with output:\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        #Check if files were uploaded\n",
    "        if not upload_widget.value:\n",
    "            print(\"No files uploaded\")\n",
    "            return\n",
    "        try:\n",
    "        # Get uploaded image\n",
    "            uploaded_file = upload_widget.value[0]  # Tuple access\n",
    "            image = Image.open(uploaded_file['content'])\n",
    "            img_array = np.array(image)\n",
    "        \n",
    "        # Convert to OpenCV format\n",
    "            test_img = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)\n",
    "            test_img = cv2.resize(test_img, (1165, 455))\n",
    "            blur_test_img = cv2.GaussianBlur(test_img, (5,5), 0)\n",
    "            gray_test_image = cv2.cvtColor(blur_test_img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Display original image\n",
    "            plt.figure(figsize=(10,6))\n",
    "            plt.imshow(img_array)\n",
    "            plt.title(\"Uploaded Image\")\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "        \n",
    "            print(\"Processing Image...\")\n",
    "        \n",
    "        # Feature analysis\n",
    "            results, avg_ssim, max_ssim = testFeature_1_2_7(gray_test_image, test_img, blur_test_img, denomination_widget.value)\n",
    "        \n",
    "        # Display results\n",
    "            print(\"\\nResults:\")\n",
    "            print(f\"Authentic Features: {sum(1 for x in results if x[2] == 'Pass')}/7\")\n",
    "            print(f\"Average SSIM: {avg_ssim:.2f}\")\n",
    "            print(f\"Max SSIM: {max_ssim:.2f}\")\n",
    "        \n",
    "        # Feature visualization\n",
    "            print(\"\\nFeature Analysis:\")\n",
    "            fig, axes = plt.subplots(len(results), 2, figsize=(15, 5*len(results)))\n",
    "            for idx, (feature_img, ssim_score, status) in enumerate(results):\n",
    "                axes[idx,0].imshow(cv2.cvtColor(feature_img, cv2.COLOR_BGR2RGB))\n",
    "                axes[idx,0].set_title(f\"Feature {idx+1}\")\n",
    "                axes[idx,0].axis('off')\n",
    "            \n",
    "                axes[idx,1].text(0.1, 0.6, f\"SSIM: {ssim_score:.2f}\\nStatus: {status}\", \n",
    "                           fontsize=12, \n",
    "                           color='green' if status == \"Pass\" else 'red')\n",
    "                axes[idx,1].axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "        # Additional processing\n",
    "            left_bleed_lines = testFeature_8(test_img, denomination_widget.value)\n",
    "            right_bleed_lines = testFeature_9(test_img, denomination_widget.value)\n",
    "            number_panel = testFeature_10(test_img, denomination_widget.value)\n",
    "        \n",
    "        # Authentication results\n",
    "            min_ssim_score_list = [0.45,0.4,0.45,0.45,0.5,0.4,0.5] if denomination_widget.value == \"2000\" else [0.4,0.4,0.5,0.4,0.5,0.45,0.5]\n",
    "            successful_features_count = 0\n",
    "            result_list = []\n",
    "        \n",
    "        # Feature validation\n",
    "            for i in range(NUM_OF_FEATURES):\n",
    "                avg_score = avg_ssim_list[i]\n",
    "                img, max_score = best_extracted_img_list[i]\n",
    "                min_allowed_score = min_ssim_score_list[i]\n",
    "            \n",
    "                status = \"Pass\" if (avg_score >= min_allowed_score or max_score >= 0.79) else \"Fail\"\n",
    "                successful_features_count += 1 if status == \"Pass\" else 0\n",
    "                result_list.append((f\"Feature {i+1}\", status, avg_score))\n",
    "            \n",
    "        # Final verification\n",
    "            success_rate = (successful_features_count / 10) * 100\n",
    "            result_html = f\"\"\"\n",
    "            <h3>Authentication Result</h3>\n",
    "            <div style='color: {\"green\" if success_rate >= 50 else \"red\"}; font-size: 20px;'>\n",
    "            Currency Note is {\"AUTHENTIC\" if success_rate >= 50 else \"FAKE\"} ({success_rate:.1f}% features verified)\n",
    "            </div>\n",
    "            \"\"\"\n",
    "            display(HTML(result_html))\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image: {str(e)}\")\n",
    "            return\n",
    "# Set up event handlers\n",
    "upload_widget.observe(process_image, names='value')\n",
    "\n",
    "# Display widgets\n",
    "display(denomination_widget)\n",
    "display(upload_widget)\n",
    "display(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac9e8a2a-fc46-4a13-b888-cc8ce2028228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# st.title(\"Currency Note Authentication\")\n",
    "# denomination = st.selectbox(\"Select Denomination of Note\", [\"500\", \"2000\"])\n",
    "# uploaded_file = st.file_uploader(\"Upload a currency note image\", type=[\"jpg\", \"png\", \"jpeg\"])\n",
    "\n",
    "\n",
    "# if uploaded_file is not None:\n",
    "#     image = load_image(uploaded_file)\n",
    "#     st.image(image, caption=\"Uploaded Image\", use_column_width=True)\n",
    "    \n",
    "#     test_img = cv2.resize(image, (1165,455))\n",
    "#     blur_test_img = cv2.GaussianBlur(test_img, (5,5), 0)\n",
    "#     gray_test_image = cv2.cvtColor(blur_test_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#     st.subheader(\"Processing Image...\")\n",
    "    \n",
    "#     results, avg_ssim, max_ssim =testFeature_1_2_7(gray_test_image, test_img, blur_test_img, denomination)\n",
    "    \n",
    "#     st.subheader(\"Results\")\n",
    "#     st.write(f\"**Number of authentic features:** {sum(1 for x in results if x[2] == 'Pass')}/7\")\n",
    "#     st.write(f\"**Average SSIM Score:** {avg_ssim:.2f}\")\n",
    "#     st.write(f\"**Maximum SSIM Score:** {max_ssim:.2f}\")\n",
    "    \n",
    "#     st.subheader(\"Feature Analysis\")\n",
    "#     for idx, (feature_img, ssim_score, status) in enumerate(results):\n",
    "#         col1, col2 = st.columns([1, 2])\n",
    "#         with col1:\n",
    "#             st.image(feature_img, caption=f\"Feature {idx+1}\", use_column_width=True)\n",
    "#         with col2:\n",
    "#             st.write(f\"**SSIM Score:** {ssim_score:.2f}\")\n",
    "#             st.write(f\"**Status:** {status}\")\n",
    "    \n",
    "#     st.subheader(\"Additional Feature Analysis\")\n",
    "    \n",
    "#     # testFeature_1_2_7(gray_test_image, test_img, blur_test_img, denomination)\n",
    "#     left_bleed_lines = testFeature_8(image, denomination)\n",
    "#     right_bleed_lines = testFeature_9(image,denomination)\n",
    "#     number_panel = testFeature_10(image,denomination)\n",
    "    \n",
    "    \n",
    "#     # st.image(left_bleed_lines, caption=\"Left Bleed Lines\", use_column_width=True)\n",
    "#     # st.image(right_bleed_lines, caption=\"Right Bleed Lines\", use_column_width=True)\n",
    "#     # st.image(number_panel, caption=\"Number Panel\", use_column_width=True)\n",
    "#     if (denomination == \"2000\"):\n",
    "#         min_ssim_score_list = [0.45, 0.4, 0.45, 0.45, 0.5, 0.4, 0.5]\n",
    "#     else:\n",
    "#         min_ssim_score_list = [0.4, 0.4, 0.5, 0.4, 0.5, 0.45, 0.5]\n",
    "#     successful_features_count = 0\n",
    "#     result_list = []\n",
    "#     # Feature 1 to 7 analysis \n",
    "#     for i in range(NUM_OF_FEATURES):\n",
    "#         avg_score = avg_ssim_list[i]\n",
    "#         img, max_score = best_extracted_img_list[i]\n",
    "#         min_allowed_score = min_ssim_score_list[i]\n",
    "        \n",
    "#         if avg_score >= min_allowed_score or max_score >= 0.79:\n",
    "#             successful_features_count += 1\n",
    "#             status = \"Pass\"\n",
    "#         else:\n",
    "#             status = \"Fail\"\n",
    "            \n",
    "#         result_list.append((f\"Feature {i+1}\", status, avg_score))\n",
    "#     # Feature 8 - Left Bleed Lines\n",
    "#     img, line_count = left_BL_result\n",
    "#     if denomination == \"2000\":\n",
    "#         ll = 6.7\n",
    "#         hl = 7.6\n",
    "#     else:\n",
    "#         ll = 4.7\n",
    "#         hl = 5.6\n",
    "\n",
    "#     if ll <= line_count <= hl:\n",
    "#         successful_features_count += 1\n",
    "#         status = \"Pass\"\n",
    "#     else:\n",
    "#         status = \"Fail\"\n",
    "#     result_list.append((\"Left Bleed Lines\", status, line_count))\n",
    "#     # Feature 9 - Right Bleed Lines  \n",
    "#     img, line_count = right_BL_result\n",
    "#     if ll <= line_count <= hl:\n",
    "#         successful_features_count += 1\n",
    "#         status = \"Pass\"\n",
    "#     else:\n",
    "#         status = \"Fail\"\n",
    "#     result_list.append((\"Right Bleed Lines\", status, line_count))\n",
    "#     # Feature 10 - Number Panel\n",
    "#     img, number_panel_status = number_panel_result\n",
    "#     if number_panel_status:\n",
    "#         successful_features_count += 1\n",
    "#         status = \"Pass\"\n",
    "#     else:\n",
    "#         status = \"Fail\"\n",
    "#     result_list.append((\"Number Panel\", status, number_panel))\n",
    "#     # Display final results\n",
    "#     st.subheader(\"Authentication Result\")\n",
    "    \n",
    "#     success_rate = (successful_features_count / 10) * 100\n",
    "    \n",
    "#     if success_rate >= 50:\n",
    "#         st.success(f\"Currency Note is AUTHENTIC ({success_rate:.1f}% features verified)\")\n",
    "#     else:\n",
    "#         st.error(f\"Currency Note appears to be FAKE ({success_rate:.1f}% features verified)\")\n",
    "#     # Display detailed results table\n",
    "#     st.write(\"Detailed Feature Analysis:\")\n",
    "#     for feature, status, score in result_list:\n",
    "#         if isinstance(score, float):\n",
    "#             score_text = f\"{score:.2f}\"\n",
    "#         else:\n",
    "#             score_text = str(score)\n",
    "            \n",
    "#         if status == \"Pass\":\n",
    "#             st.success(f\"{feature}: {score_text}\")\n",
    "#         else:\n",
    "#             st.error(f\"{feature}: {score_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdc7e9b-9fae-4781-854e-0cac1436ed74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f807d79e-8583-4ae3-9982-7f4983c8aada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24479b3-4387-45c7-9add-c64ebf4dfdc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4faabc9-2d28-43de-a07b-fed0a0be6908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1a749a-2d6e-4d67-85d5-f51a7071dc8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0873320-9a4c-48c3-9448-4e7353141114",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
